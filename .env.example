API_TOKEN=change-me
REDIS_URL=redis://redis:6379/0
# LLM settings (local preferred)
LLM_PROVIDER=ollama
# Generic model name (used by Ollama and OpenAI branches)
OPENAI_MODEL=qwen2:7b
# If you switch to OpenAI:
OPENAI_API_KEY=
# Analysis limits
MAX_STATUS_LONGPOLL_SECONDS=1200
MAX_SERVICE_WAIT_MINUTES=15
# Ollama base URL (inside Docker use host.docker.internal)
OLLAMA_BASE_URL=http://host.docker.internal:11434
